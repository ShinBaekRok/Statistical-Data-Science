---
title: "STAT346: Statistical Data Science I"
subtitle: "Midterm Exam: Monday, November 2, 2020, 07:00--09:30 p.m."
author: "ShinBaekROk / 2019150445"
output:
  pdf_document: default
  word_document: default
fontsize: 11pt
---

```{r setup, include=FALSE}
library(tidyverse)
library(mosaic)
library(NHANES)
library(mosaicData)
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4, fig.align ="center", out.width = "80%", warning=FALSE, message=FALSE) # global options
```



# Instructions
1. This exam covers material from **Introduction to Data Science** (https://rafalab.github.io/dsbook/), Chapter 1--19.


1. You may use any books or online resources you want during this examination,
but you may not communicate with any person other than your examiner.

1. You are required to use the RStudio IDE for this exam. You may use either
the desktop edition or rstudio.cloud as you prefer.

1. You should work on the provided exam template.
When you finalize your exam, you should submit your paper in pdf 
as well as its .rmd source file. They should have the following name:

   + `stat346_mid_yourID.pdf` 
   + `stat346_mid_yourID.rmd`

1. You should submit your paper no later than 9:30 p.m. 
If you are late, you will get 20% penalty per 10 minutes. 

---

# Problem Set \#1 (10 Points)

Using the famous `Galton` data set from the 
`mosaicData` package:

```{r}
library(mosaic)
data(Galton)
```

Use the `ggplot2` package to answer the followings:

   (a) [5 points] Create a scatterplot of each person's height against
   their father's height.
   
   + (sol) 
   
```{r}
   Galton %>% ggplot(aes(y=height,x=father))+geom_point()
```
   
   (b) [5 points] Seprate your plot into facets by sex. 
   Add regression lines to all of your facets. 

   + (sol)
```{r}
   Galton %>% ggplot(aes(y=height,x=father))+geom_point()+facet_grid(.~sex)+geom_smooth(method='lm')
```
 

# Problem Set \#2 (15 Points)

The file `ranking.csv` contains two columns:

- The ID of an item being rated.
- A rating, which is one of `negative`, `positive`, `indifferent`, or `wtf`
(meaning the respondent didn't understand the question).

There are multiple ratings for each item. The plot below shows this data:

- Each dot represents one item `i`.
- The size of the circles shows the total number of ratings for item `i`.
- The `X` coordinate for item `i` is the percentage of ratings for that item that
are `negative`.
- The `Y` coordinate for item `i` is the percentage of ratings for that item that
are `positive`.
- The regression line is created using the `lm` method.

```{r echo=FALSE}
#knitr::include_graphics("ranking-scatterplot-1.png")
```

Re-create this plot using the `tidyverse` and `ggplot2`, fixing any mistakes you
notice along the way.

 
+ (sol) 
```{r}
data.q2 <- read.csv('C:/ranking.csv')
       
dt.q2 <- data.q2 %>%  group_by(item) %>%
   summarise(negative = sum(rank=='negative')/length(item),
   positive = sum(rank=='positive')/length(item),
   num = length(item))

dt.q2 %>% ggplot(mapping=aes(x=negative, y=positive)) +
   geom_point(aes(size=num)) +
   geom_smooth(method=lm, formula = y~x)
```
# Problem Set \#3 (20 Points)


Read the file `measurements.csv` to create a tibble called `measurements`. (The strings `rad`, `sal`, and `temp` in the quantity column stand for `radiation`, `salinity`, and `temperature`, respectively.)

   (a) [5 points] Create a tibble containing only rows where none of the values are `NA` and save in a tibble called `cleaned`.

   + (sol)
```{r}
measurements<-read_csv('C:/measurements.csv')
cleaned<- measurements %>% filter(!is.na(visitor) & !is.na(reading))# NA are only in visitor and reading
cleaned
```

   (b) [5 points] Count the number of measurements of each type of quantity in `cleaned`. Your result should have one row for each quantity `rad`, `sal`, and `temp`.
   
   + (sol)
```{r}
rad<-cleaned %>% filter(quantity=='rad') %>% summarize(n=n()) %>% pull(n)

sal<-cleaned %>% filter(quantity=='sal') %>% summarize(n=n()) %>% pull(n)

temp<-cleaned %>% filter(quantity=='temp') %>% summarize(n=n()) %>% pull(n)

data.frame(number=c(rad=rad,sal=sal,temp=temp))

```

   (c) [5 points] Display the minimum and maximum value of reading separately for each quantity in `cleaned`. Your result should have one row for each quantity `rad`, `sal`, and `temp`.
   
   + (sol)
```{r}
rad_max<-cleaned %>% filter(quantity=='rad') %>% .$reading %>% max()
rad_min<-cleaned %>% filter(quantity=='rad') %>% .$reading %>% min()

sal_max<-cleaned %>% filter(quantity=='sal') %>% .$reading %>% max()
sal_min<-cleaned %>% filter(quantity=='sal') %>% .$reading %>% min()

temp_max<-cleaned %>% filter(quantity=='temp') %>% .$reading %>% max()
temp_min<-cleaned %>% filter(quantity=='temp') %>% .$reading %>% min()

x<-data.frame(max=c(rad_max,sal_max,temp_max),min=c(rad_min,sal_min,temp_min))
rownames(x)<-c('rad','sal','temp')
x
```

   (d) [5 points] Create a tibble in which all salinity (`sal`) readings greater than 1 are divided by 100. (This is needed because some people wrote percentages as numbers from 0.0 to 1.0, but others wrote them as 0.0 to 100.0.)
   
   + (sol)
```{r}
cleaned %>%  filter(quantity=='sal' & reading>1) %>% mutate(reading=reading/100) %>% pull(reading)
cleaned[14,4]<-0.416
cleaned[17,4]<-0.225
cleaned
```

# Problem Set \#4 (35 Points)

For this problem, we will be using the data from the survey collected by the United States National Center for Health Statistics (NCHS). This center has conducted a series of health and nutrition surveys since the 1960's. Starting in 1999, about 5,000 individuals of all ages have been interviewed every year and they complete the health examination component of the survey. 

Part of the data is made available via the `NHANES` package. Once you install the `NHANES` package, you can load the data like this:

```{r}
library(NHANES)
data(NHANES)
```

Let's now explore the `NHANES` data.

   (a) [5 points] We will provide some basic facts about blood pressure. First let's select a group to set the standard. We will use 20-to-29-year-old females. `AgeDecade` is a categorical variable with these ages. Note that the category is coded like `" 20-29"`, with a space in front! What is the average and standard deviation of systolic blood pressure as saved in the `BPSysAve` variable? Save it to a variable called `ref`.
   
   + (sol)
```{r}
ref<-NHANES %>% filter(AgeDecade==' 20-29', Gender=='female', !is.na(BPSysAve)) %>% summarize(mean=mean(BPSysAve),sd=sd(BPSysAve))
ref
```

   (b) [5 points] Using a pipe, assign the average to a numeric variable `ref_avg`. 
   
   + (sol)
```{r}
ref_avg <-ref %>% pull(mean)
```

   (c) [5 points] Now report the min and max values for the same group.
   
   + (sol)
```{r}
NHANES %>% filter(AgeDecade==' 20-29', Gender=='female', !is.na(BPSysAve)) %>% summarize(min=min(BPSysAve),max=max(BPSysAve))
```

   (d) [5 points] Compute the average and standard deviation for females, but for each age group separately rather than a selected decade as in   (a). Note that the age groups are defined by `AgeDecade`. 
   
   + (sol)
```{r}
NHANES %>% filter(Gender=='female' & !is.na(BPSysAve)) %>% group_by(AgeDecade) %>% summarize(mean=mean(BPSysAve),sd=sd(BPSysAve))
```
   (e) [5 points] Repeat (d) for males. 
   
   + (sol)
```{r}
NHANES %>% filter(Gender=='male' & !is.na(BPSysAve)) %>% group_by(AgeDecade) %>% summarize(mean=mean(BPSysAve),sd=sd(BPSysAve))

```
   (f) [5 points] We can actually combine both summaries for  (d) and (e) into one line of code. This is because `group_by` permits us to group by more than one variable. Obtain one big summary table using `group_by(AgeDecade, Gender)`.
   
   + (sol)
```{r}
NHANES %>% filter(!is.na(BPSysAve)) %>% group_by(AgeDecade,Gender) %>% summarize(mean=mean(BPSysAve),sd=sd(BPSysAve))
```
   (g) [5 points] For males between the ages of 40-49, compare systolic blood pressure across race as reported in the `Race1` variable. Order the resulting table from lowest to highest average systolic blood pressure.
   
   + (sol)
```{r}
NHANES %>% filter(Gender == "male" & AgeDecade == " 40-49" & !is.na(BPSysAve)) %>%
    group_by(Race1) %>%
    summarize(mean=mean(BPSysAve),sd=sd(BPSysAve)) %>%
    arrange(mean)
```
# Problem Set \#5 (20 Points)


   (a) [5 points]  Two teams, say the Celtics and the Cavs, are playing a seven game series. The Cavs are a better team and have a 60% chance of winning each game. What is the probability that the Celtics win **at least** one game? Calculate it by hand.
   
   + (sol)
```{r}
Cavs_win_prob<-0.6
1-(Cavs_win_prob)^4

```
   (b) [5 points]  Create a Monte Carlo simulation to confirm your answer to the previous problem. Use `B <- 10000` simulations. 
   
   + (sol)
```{r}
B<-10000
result<-replicate(B,{
   x<-sample(c(0,1),4,replace=TRUE,prob=c(0.6,0.4))
   sum(x)>=1
})
mean(result)
```

   (c) [5 points]  Again, two teams are playing a seven game championship series. The first to win four games, therefore, wins the series. Now, the teams are equally good so they each have a 50-50 chance of winning each game. If the Cavs lose the first game, what is the probability that they win the series? Calculate it by hand.
   
   + (sol)
```{r}
expand.grid(rep(list(0:1),6)) %>% rowSums(.)>=4->x
mean(x)
```

   (d) [5 points]  Confirm the results of the previous question with a Monte Carlo simulation. Use `B <- 10000` simulations.
   
   + (sol)
```{r}
B<-10000
result<-replicate(B,{
   x<-sample(c(0,1),6,replace=TRUE,prob=c(0.5,0.5))
   sum(x)>=4
})
mean(result)
```

# Problem Set \#6 (20 Points)

**Bootstrapping** is any test or metric that uses random sampling with replacement and falls under the broader class of resampling methods. This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods.

For illustration, read the following code:
```{r}
library(tidyverse)
d=tibble(x=c(1,2,3,4,5,6,7,8,9,10),
         y=c(7,3,4,2,10,1,9,8,5,6))
cor(d$x,d$y)
```

The correlation between `x` and `y` is given by 0.224. 
Now suppose that we wish to find its standard error (SE),
which is in fact not a simple task. Bootstrapping comes to its rescue,
providing approximated SE estimates.  

```{r}
B = 1000; n=nrow(d)
cor_boot=replicate(B,{
    d_temp = sample_n(d,n,replace=TRUE)
    cor(d_temp$x,d_temp$y)
})
sd(cor_boot)
```

With this idea, answer the followings for
`Gestation` data set from the `mosaicData` package. 

```{r}
library(mosaicData)
data(Gestation)
```

   (a) [6 points] Calculate and interpret a 95% confidence interval
   for the mean age of mothers.
   
   + (sol)
```{r}
mean<-Gestation$age %>% mean(na.rm=T)
sd<-Gestation$age %>% sd(na.rm=T)
se<-sd/sqrt(length(Gestation$age))
CI<-c(mean-qnorm(0.975)*se,mean+qnorm(0.975)*se)
CI
```
when we were to take repeated samples and construct for 95%CI for each sample,then 95% of these intervals would be expected to contain the true mean value. 

   (b) [6 points] Use the bootstrap to generate and interpret 
   a 95% confidence interval for the median age of mothers. 
   
   + (sol)
```{r}
B = 1000
      n <- nrow(data.q6.a)
      boot = replicate(B, {
             d_temp = sample_n(data.q6.a, n, replace=TRUE)
             d_med = median(d_temp$age)
            })
      age_med = mean(boot)
      age_sd = sd(boot)
      data.frame(boot.median=age_med,
                lower=age_med - 1.96*age_sd,
                upper=age_med + 1.96*age_sd)
               
            
      # There should be Interpretation of CI in your result pdf
```
when we were to take repeated samples and construct for 95%CI for each sample,then 95% of these intervals would be expected to contain the true median value.


   (d) [8 points] Use the bootstrap to generate a 95% confidence
   interval for the regression parameters in a model
   for weight (`wt`) as a function of `age`. 
   
   + (sol)
```{r}
 ###########################
       # for intercept parameter #
       ###########################
       
     data.q6.c <- na.omit(as.data.frame(data.q6[,c('id','age','wt')]))
     n <- nrow(data.q6.c)    
     B = 1000
     
     boot_interc = replicate(B, {
                d_temp = sample_n(data.q6.c, n, replace=TRUE)
                lm = lm(wt ~ age, data=d_temp)$coef[1]
            })
     coef0_mean = mean(boot_interc)
     coef0_sd = sd(boot_interc)
     data.frame(boot.intercept=coef0_mean,
                lower=coef0_mean - 1.96*coef0_sd,
                upper=coef0_mean + 1.96*coef0_sd)
               
               
       ##########################
       ## for slope parameter ##
       ##########################
       
     B = 1000
     boot_slope = replicate(B, {
                d_temp = sample_n(data.q6.c, n, replace=TRUE)
                lm = lm(wt ~ age, data=d_temp)$coef[2]
            })
     coef1_mean = mean(boot_slope)
     coef1_sd = sd(boot_slope)
     data.frame(boot.coef1=coef1_mean,
                lower=coef1_mean - 1.96*coef1_sd,
                upper=coef1_mean + 1.96*coef1_sd)
```
